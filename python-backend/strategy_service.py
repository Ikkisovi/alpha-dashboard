"""
Lightweight strategy computation service.
It consumes cached factor signals + target returns generated by compute_service.py
and runs a fast portfolio backtest (no IC/VIF analytics).
"""
import sys
import json
import time
from pathlib import Path
from typing import List, Optional, Tuple

import numpy as np

SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
QLIB_DATA_DIR = PROJECT_ROOT / "data" / "1555_qlib"
BACKTRACK_DAYS = 100
FUTURE_DAYS = 30


def load_close_prices(qlib_path: str, start_date: str, end_date: str) -> Tuple[List["pd.Timestamp"], List[str], np.ndarray]:
    """Slow fallback loader that reads .bin files directly."""
    import pandas as pd

    qlib_dir = Path(qlib_path)
    calendar_file = qlib_dir / "calendars" / "day.txt"
    with open(calendar_file, "r") as f:
        all_dates = [pd.Timestamp(line.strip()) for line in f if line.strip()]

    start_ts = pd.Timestamp(start_date)
    end_ts = pd.Timestamp(end_date)
    start_idx = next((i for i, d in enumerate(all_dates) if d >= start_ts), 0)
    end_idx = next((i for i, d in enumerate(all_dates) if d > end_ts), len(all_dates))
    start_idx = max(0, start_idx - BACKTRACK_DAYS)
    end_idx = min(len(all_dates), end_idx + FUTURE_DAYS)

    dates = all_dates[start_idx:end_idx]
    instruments_file = qlib_dir / "instruments" / "all.txt"
    stock_ids: List[str] = []
    with open(instruments_file, "r") as f:
        for line in f:
            parts = line.strip().split("\t")
            if parts:
                stock_ids.append(parts[0].lower())

    n_days = len(dates)
    n_stocks = len(stock_ids)
    close_prices = np.full((n_days, n_stocks), np.nan, dtype=np.float32)

    features_dir = qlib_dir / "features"
    for s_idx, stock_id in enumerate(stock_ids):
        close_file = features_dir / stock_id / "close.day.bin"
        if not close_file.exists():
            continue
        with open(close_file, "rb") as f:
            data = np.fromfile(f, dtype="<f")
        if len(data) >= end_idx:
            close_prices[:, s_idx] = data[start_idx:end_idx]
        elif len(data) > start_idx:
            available = min(len(data) - start_idx, n_days)
            close_prices[:available, s_idx] = data[start_idx:start_idx + available]
    return dates, stock_ids, close_prices


def load_factor_cache(path: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[List[str]]]:
    """Load cached combined signal/target returns metadata."""
    try:
        with np.load(path, allow_pickle=True) as payload:
            signal = payload["signal"] if "signal" in payload.files else None
            target_returns = payload["target_returns"] if "target_returns" in payload.files else None
            cache_dates = payload["dates"] if "dates" in payload.files else None
    except Exception as exc:  # pylint: disable=broad-except
        print(f"Failed to load cached factor signals from {path}: {exc}", file=sys.stderr)
        return None, None, None

    dates_list: Optional[List[str]] = None
    if cache_dates is not None:
        if isinstance(cache_dates, np.ndarray):
            dates_list = [str(d) for d in cache_dates.tolist()]
        else:
            dates_list = [str(cache_dates)]
    return signal, target_returns, dates_list


def compute_strategy_returns(
    factor_signals: np.ndarray,
    stock_returns: np.ndarray,
    date_strings: List[str],
    train_start: str,
    train_end: str,
    test_start: str,
    test_end: str,
    top_pct: float,
    strat_type: str,
    rebalance_days: int,
    horizon_days: int,
) -> dict:
    import pandas as pd

    if factor_signals.shape != stock_returns.shape:
        raise ValueError(f"Shape mismatch between factor signals {factor_signals.shape} and stock returns {stock_returns.shape}")
    if len(date_strings) != factor_signals.shape[0]:
        raise ValueError("Date metadata length mismatch; regenerate cached signals.")

    def compute_daily_ic(signals: np.ndarray, returns: np.ndarray) -> np.ndarray:
        ic = np.full(signals.shape[0], np.nan, dtype=np.float32)
        for t in range(signals.shape[0]):
            s = signals[t]
            r = returns[t]
            mask = np.isfinite(s) & np.isfinite(r)
            if mask.sum() < 2:
                continue
            s_m = s[mask]
            r_m = r[mask]
            s_std = s_m.std()
            r_std = r_m.std()
            if s_std < 1e-12 or r_std < 1e-12:
                continue
            ic[t] = np.corrcoef(s_m, r_m)[0, 1]
        return ic

    dates = pd.to_datetime(date_strings)
    train_start_ts = pd.Timestamp(train_start)
    train_end_ts = pd.Timestamp(train_end)
    test_start_ts = pd.Timestamp(test_start)
    test_end_ts = pd.Timestamp(test_end)

    daily_ic = compute_daily_ic(factor_signals, stock_returns)

    signals = np.nan_to_num(factor_signals, nan=0.0).astype(np.float32)
    returns = np.clip(np.nan_to_num(stock_returns, nan=0.0), -0.9, 0.5).astype(np.float32)

    T, N = signals.shape
    pct = max(min(float(top_pct), 0.5), 0.01)
    step = max(int(rebalance_days), 1)

    port_ret = np.zeros(T, dtype=np.float32)
    benchmark_ret = np.zeros(T, dtype=np.float32)
    rebalance_ids = np.zeros(T, dtype=np.int32)

    ranks = np.argsort(np.argsort(signals, axis=1), axis=1).astype(np.float32)

    rebalance_idx = 0
    for start in range(0, T, step):
        end = min(start + step, T)
        row_ranks = ranks[start]
        long_mask = row_ranks >= (N * (1 - pct))
        short_mask = row_ranks < (N * pct)

        weights = np.zeros(N, dtype=np.float32)
        long_count = max(int(long_mask.sum()), 1)
        short_count = max(int(short_mask.sum()), 1)
        weights[long_mask] = 1.0 / long_count
        if strat_type == "long_short":
            weights[short_mask] = -1.0 / short_count
        elif strat_type == "equal_weight":
            weights[:] = 1.0 / max(N, 1)

        window_rets = returns[start:end]
        stock_cum = np.cumprod(1.0 + window_rets, axis=0)
        portfolio_nav = 1.0 + np.sum(weights * (stock_cum - 1.0), axis=1)
        prev_nav = np.concatenate(([1.0], portfolio_nav[:-1]))
        daily = portfolio_nav / np.maximum(prev_nav, 1e-8) - 1.0
        port_ret[start:end] = daily
        rebalance_ids[start:end] = rebalance_idx
        rebalance_idx += 1

    valid_mask = ~np.isnan(returns[0])
    v_count = max(int(valid_mask.sum()), 1)
    init_weights = np.zeros(N, dtype=np.float32)
    init_weights[valid_mask] = 1.0 / v_count
    bench_cum = np.cumprod(1.0 + returns, axis=0)
    bench_nav = np.sum(init_weights * bench_cum, axis=1)
    prev_bench = np.concatenate(([1.0], bench_nav[:-1]))
    benchmark_ret = bench_nav / np.maximum(prev_bench, 1e-8) - 1.0

    train_mask = (dates >= train_start_ts) & (dates <= train_end_ts)
    test_mask = (dates >= test_start_ts) & (dates <= test_end_ts)

    def calc_metrics(ret_slice: np.ndarray, ic_slice: np.ndarray, period_name: str) -> Optional[dict]:
        if ret_slice.size == 0:
            return None
        avg_ret = float(np.mean(ret_slice))
        std_ret = float(np.std(ret_slice))
        sharpe = (avg_ret / (std_ret + 1e-9)) * np.sqrt(252)
        cum = np.cumprod(1 + ret_slice)
        run_max = np.maximum.accumulate(cum)
        dd = (cum - run_max) / run_max
        mdd = float(np.min(dd))
        ic_mean = float(np.nanmean(ic_slice)) if ic_slice.size > 0 else 0.0
        ic_std = float(np.nanstd(ic_slice)) if ic_slice.size > 0 else 0.0
        icir = ic_mean / (ic_std + 1e-9)
        return {
            "factor_id": -1,
            "factor_name": f"Strategy ({strat_type})",
            "horizon_days": int(horizon_days),
            "period": period_name,
            "ic": ic_mean,
            "ic_std": ic_std,
            "icir": icir,
            "ric": 0,
            "sharpe": float(sharpe),
            "annual_return": float(avg_ret * 252),
            "daily_return_mean": avg_ret,
            "max_drawdown": mdd,
        }

    metrics: List[dict] = []
    daily_returns: List[dict] = []

    if train_mask.any():
        train_ret = port_ret[train_mask]
        m = calc_metrics(train_ret, daily_ic[train_mask], "train")
        if m:
            metrics.append(m)
        train_dates = dates[train_mask]
        train_bench = benchmark_ret[train_mask]
        train_reb = rebalance_ids[train_mask]
        for d, r, b, rid in zip(train_dates, train_ret, train_bench, train_reb):
            daily_returns.append({
                "date": d.strftime("%Y-%m-%d"),
                "factor_id": -1,
                "horizon_days": int(horizon_days),
                "return": float(r),
                "benchmark": float(b),
                "rebalance_id": int(rid),
            })

    if test_mask.any():
        test_ret = port_ret[test_mask]
        m = calc_metrics(test_ret, daily_ic[test_mask], "test")
        if m:
            metrics.append(m)
        test_dates = dates[test_mask]
        test_bench = benchmark_ret[test_mask]
        test_reb = rebalance_ids[test_mask]
        for d, r, b, rid in zip(test_dates, test_ret, test_bench, test_reb):
            daily_returns.append({
                "date": d.strftime("%Y-%m-%d"),
                "factor_id": -1,
                "horizon_days": int(horizon_days),
                "return": float(r),
                "benchmark": float(b),
                "rebalance_id": int(rid),
            })

    return {
        "metrics": metrics,
        "daily_returns": daily_returns,
        "computation_time_ms": 0,
    }


def main():
    try:
        input_data = sys.stdin.read()
        request = json.loads(input_data) if input_data.strip() else {}

        t0 = time.time()
        train_start = request.get("train_start", "2022-01-01")
        train_end = request.get("train_end", "2023-12-31")
        test_start = request.get("test_start", "2024-01-01")
        test_end = request.get("test_end", "2024-12-31")

        strategy_cfg = request.get("strategy", {}) or {}
        strat_type = strategy_cfg.get("type", "long_short")
        top_pct = strategy_cfg.get("top_pct", 0.2)
        rebalance_days = strategy_cfg.get("rebalance_days", 1)

        target_horizons = request.get("target_horizons") or request.get("targetHorizons") or request.get("target_horizon")
        horizon_days = 1
        if isinstance(target_horizons, list) and target_horizons:
            try:
                horizon_days = int(target_horizons[0])
            except (TypeError, ValueError):
                horizon_days = 1
        elif isinstance(target_horizons, (int, float, str)):
            try:
                horizon_days = int(target_horizons)
            except (TypeError, ValueError):
                horizon_days = 1
        horizon_days = max(int(horizon_days), 1)

        factor_signal_path = request.get("factor_signal_path")
        factor_signals = None
        stock_returns = None
        signal_dates: Optional[List[str]] = None

        if factor_signal_path:
            factor_signals, stock_returns, signal_dates = load_factor_cache(factor_signal_path)

        if factor_signals is None:
            provided = request.get("factor_signals")
            if provided is not None:
                factor_signals = np.array(provided, dtype=np.float32)

        if factor_signals is None:
            raise ValueError("Factor signals missing; ensure pool_id/factor selections are provided.")

        if stock_returns is None or signal_dates is None or len(signal_dates) != factor_signals.shape[0]:
            dates, _, close_prices = load_close_prices(str(QLIB_DATA_DIR), train_start, test_end)
            stock_returns = np.zeros_like(close_prices, dtype=np.float32)
            stock_returns[1:] = close_prices[1:] / np.maximum(close_prices[:-1], 1e-8) - 1
            stock_returns = np.nan_to_num(stock_returns, nan=0.0)
            signal_dates = [d.strftime("%Y-%m-%d") for d in dates]
            if stock_returns.shape != factor_signals.shape:
                min_len = min(stock_returns.shape[0], factor_signals.shape[0])
                stock_returns = stock_returns[-min_len:]
                factor_signals = factor_signals[-min_len:]
                signal_dates = signal_dates[-min_len:]

        result = compute_strategy_returns(
            factor_signals=factor_signals,
            stock_returns=stock_returns,
            date_strings=signal_dates,
            train_start=train_start,
            train_end=train_end,
            test_start=test_start,
            test_end=test_end,
            top_pct=top_pct,
            strat_type=strat_type,
            rebalance_days=rebalance_days,
            horizon_days=horizon_days,
        )
        result["computation_time_ms"] = (time.time() - t0) * 1000.0
        print(json.dumps(result))
    except Exception as exc:  # pylint: disable=broad-except
        import traceback

        print(json.dumps({
            "error": str(exc),
            "traceback": traceback.format_exc(),
        }))
        sys.exit(1)


if __name__ == "__main__":
    main()
